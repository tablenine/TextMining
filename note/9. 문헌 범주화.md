### 9-1 문헌 범주화 소개

+ Document Classification (Text Classification)
+ 두 개 이상의 미리 정해진 붐주에 문서를 분류하는 과정
  + 문헌 -> 문헌 분류기 -> ex) 정치 or 스포츠 or 경제
+ 문헌 범주화 사용 예시
  + 뉴스 기사 분류
  + 이메일 스팸 탐지
  + 웹문서 분류

### 9-2 문헌 표현

+ 문헌 자동 분류의 가장 기본은 자질벡터를 만드는 것
+ 문헌은 자질 벡터(Feature Vector)로 표현됨
  + 자질 (Feature)
    + 내부 구조를 갖지 않는 Entity
    + Feature Space의 차원
+ Bag of words
  + 단어의 자질로 표현함
  + Feature Space의 차원은 모든 문헌의 단어 개수와 동일
+ 문헌 범주화를 하기 위해 각 단어에 중요도(가중치)를 부여함
  + TF-IDF
    + weight<sub>w</sub> = tf<sub>w</sub> * idf<sub>w</sub>
      + tf<sub>w</sub> : 단어 w가 문헌에 나타난 빈도수
      + idf<sub>w</sub> :  log<sub>2</sub> N / dfw
        + N - 전체 문헌 갯수, dfw - 단어 w가 나타나는 문헌의 갯수
+ 문헌 수집
  + Training set
  + Test set
+ 자질 선택
  + 문헌 범주화의 효율성을 증가
  + 자질로 적합하지 않은 단어들을 제거
  + x<sup>2</sup> statistic
    + 자질과 범주들 간의 독립성 측정
    + 독립적이면 그 자질은 범주화에 영향을 미치지 않는다고 판단
  + Document frequency threshold (문헌에 나타나는 각 자질 간의 관련성을 측정) 등

### 9-3 지도 학습 기반 범주화

+ 문헌 분류기 (문헌 분류를 구체적으로 구현함)
+ 대부분 지도학습으로 사용
+ 지도학습 기반 범주화
  + 범주의 개수를 정함
  + 학습 데이터에 기반함
  + Future observation을 분류하는 데 사용됨
+ 비지도학습 기반 범주화
  + 범주의 개수를 모름
  + Prior knowledge가 없음
+ k-Nearest Neighbors(KNN)
  + 비모수적인 방법
  + 학습 문헌에 있는 문헌들은 이미 범주가 정해져 있음
  + 새로운 문헌 d의 범주는 학습 문헌들 중 유사도가 가장 높은 k개의 문헌들이 어떤 범주에 속해있는지에 따라 결정됨
  + k : 양의 정수
+ Support Vector Machine(SVM)
  + 학습 문헌들이 각 범주 안에 속해 있다고 가정
  + 새로운 문헌이 어느 범주에 속할지 판단하는 이진 선형 분류 모델
  + Margin을 최대로 하는 hyperplane을 구함
  + [LibSVM](http://www.csie.ntu.edu.tw/~cjlin/libsvm/)
    + Chin-Jen Lin 등에 의해 개발
    + (Multi-class) SV classfication과 regression을 위한 도구
    + C++/JAVA/Python/Matlab/Perl
    + Linux/UNIX/WIndows
  + [SVM-Light](http://svmlight.joachims.org/)
+ N겹 교차 검증
  + 사용 가능한 데이터는 n개의 동일한 크기로 분리된 하위 집합으로 나누어짐
  + 각 하위 집합을 test set로 두고 나머지 n-1개의 하위 집합들을 training set로 둠
  + 절차는 n번 수행되어 n개의 정확도를 제공
  + 5겹과 10겹 교차 검증이 주로 사용됨

### 9-4 비지도 학습 기반 범주화

+ K-means
  + 문헌들을 k개의 클러스터로 묶음
  + 레이블이 달려 있지 않은 새로운 문헌에 레이블을 달아줌
  + 같은 클러스터에 있는 문헌들 간의 유사도를 높이는 방향으로 클러스터를 형성

