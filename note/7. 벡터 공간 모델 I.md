### 7.1 벡터 공간 모델

+ 벡터 공간 모델
  + 텍스트 문서를 색인어와 같은 식별자들을 **벡터**로 나타내는 대수적인 모델
  + 문서는 벡터로 표현되며, 각각의 차원은 개별 단어에 대응됨
  + 만약 문서 내에 특정 단어가 포함되어 있다면. 벡터 내에서 해당 차원은 0이 아닌 값을 갖게 됨
+ 단어 가중치 (Term Weight)
  + 여러가지 계산 방법이 있으며, 가장 잘 알려진 방법 중의 하나는 TF-IDF 가중치를 구하는 방법
  + 단어는 하나의 단어이거나 키워드, 혹은 더 긴 구가 될 수 있음
  + 만약 단어가 단일어로 선택된다면, 벡터의 차원 수 (Dimensionality)는 단어집(Vocabulary) 내의 단어들의 숫자(언어 자료 내에 들어 있는 개별 단어들의 숫자)가 됨
+ 벡터 공간 모델의 응용
  + 문서벡터(Document Vector)
  + 검색의 대상이 되는 문서 : D<sub>1</sub>, D<sub>2</sub>, D<sub>3</sub>,  ...D<sub>n</sub>이고, 이와 같은 문서 집합 전체에 결쳐 전부 m개의 색인어 W<sub>1</sub>, W<sub>2</sub>, W<sub>3</sub>,  …W<sub>m</sub>
  + 문서 집합의 전체는 m * n 행렬로 표현할 수 있음
  + 문헌 * 단어  매트릭스(Document*Term Matrix)
    + 각 열은 색인어(Term Vector)
+ 벡터 공간 모델의 한계
  + 긴 문서들은 유사도 값이 작기 때문에, 제대로 표현되지 않음
  + 비슷한 의미를 갖고 있는 문서들일지라도 사용된 단어가 다르면 연관성을 갖지 못함
  + 벡터 공간 표현에서는 단어들이 나타나는 **순서가 무시되기 때문에** 문맥 정보를 파악할 수 없음

### 7-2 문헌 * 단어 매트릭스 생성

+ 문헌*단어 매트릭스 생성은 다양한 방법이 가능
  + LuceneVectorSpaceModelManager
    + 루씬을 이용해서 문헌집단을 색인한 후 문헌*단어 매트릭스를 만들 수 있음 **(먼저 색인을 해야한다는 단점이 있음)**
    + 메모리가 적게 소요되고 효율적 (**개인PC에서도 사용가능**)
  + 분산병렬방법 사용(Hadoop)
    + 루씬보다 더 복잡
    + 많은 양의 데이터 처리 가능
  + createDocumentTermMatrix 함수
    + 문헌열과 문헌집단 안에 존재하는 어휘 개수를 인수로 받음
+ 문헌집단의 수를 처리하는 데 필요한 메모리보다 코드를 실행하는 **컴퓨터의 메모리 용량이 작을 때는** 문헌*단어 매트릭스를 생성할 수 없음

### 7-3 단어 가중치 기법

+ ​